{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6072022-e8a4-4b03-a542-b99bb26d7ed3",
   "metadata": {},
   "source": [
    "<img src='data/images/section-notebook-header.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2d52db-ac20-4da9-b9ae-8d99348b2152",
   "metadata": {},
   "source": [
    "# Keyword Extraction\n",
    "\n",
    "Keyword extraction in natural language processing (NLP) is the task of automatically identifying and extracting the most important words or phrases from a piece of text. These keywords are representative of the main topics or themes present in the text. The goal is to summarize the content and capture its essence by selecting the most relevant and informative terms.\n",
    "\n",
    "Keyword extraction is widely used in various NLP applications, including document summarization, question answering, information retrieval, text classification, and topic modeling. By identifying and extracting keywords, we can gain insights into the main subjects discussed in a document or a collection of documents. This helps in organizing, categorizing, and searching textual data more efficiently.\n",
    "\n",
    "There are different approaches to keyword extraction in NLP. Some common techniques include:\n",
    "\n",
    "* **Frequency-based methods:** These methods rely on the assumption that important words occur frequently in a document compared to less important ones. They calculate statistical measures such as term frequency (TF) or term frequency-inverse document frequency (TF-IDF) to identify significant terms.\n",
    "\n",
    "* **Graph-based methods:** These methods construct a graph representation of the text, where nodes represent words or phrases, and edges represent relationships between them. Algorithms like TextRank or PageRank can be applied on the graph to determine the importance of each node and extract keywords based on their centrality scores.\n",
    "\n",
    "* **Machine learning approaches:** These methods utilize supervised or unsupervised machine learning algorithms to train models on labeled data or extract patterns from the data. Techniques such as support vector machines (SVM), Naive Bayes, or clustering algorithms can be employed for keyword extraction.\n",
    "\n",
    "* **Hybrid methods:** These methods combine multiple techniques, leveraging both statistical measures and linguistic rules to extract keywords. They often yield better results by incorporating different aspects of keyword importance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1303561a-3cca-43b9-abd8-adb22949b891",
   "metadata": {},
   "source": [
    "## Setting up the Notebook\n",
    "\n",
    "### Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92827c60-fed4-48a5-bc63-13ade9184c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1a4263-f7cc-46d5-baf5-4306eb0ca65a",
   "metadata": {},
   "source": [
    "Besides the commonly used packages, we also need the following packages in this notebook.\n",
    "\n",
    "* [Newspaper3k](https://newspaper.readthedocs.io/en/latest/) allows to download news articles, using heuristic to extract the headline and content from the web page. It also performs some basic text analysis, including a basich approach for keyword extraction.\n",
    "\n",
    "* [rake-nltk](https://pypi.org/project/rake-nltk/) is an implementation of the RAKE algorihtm covered in this notebook. This package requires NLTK to be installed.\n",
    "\n",
    "* [yake](https://pypi.org/project/yake/) is an implementation of the Yake! algorithm covered in this notebook.\n",
    "\n",
    "* [PyTextRank](https://spacy.io/universe/project/spacy-pytextrank) is an implementation of the TextRank algorithm covered in this notebook. The package requires spaCy to be installed as the algorithm is added to the spaCy pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceca2e2-2e19-4e19-bf40-269c9e26fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "from rake_nltk import Rake\n",
    "import yake\n",
    "\n",
    "from nltk.corpus import stopwords as sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa38412-a832-47c8-a02d-5d54a7d482b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pytextrank\n",
    "\n",
    "# load a spaCy model, depending on language, scale, etc.\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# add PyTextRank to the spaCy pipeline\n",
    "nlp.add_pipe(\"textrank\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8f6456-a7ac-4f2e-939e-e38e543be4aa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d620c4d3-8fc2-4247-8bde-03f542811071",
   "metadata": {},
   "source": [
    "## Fetch News Article\n",
    "\n",
    "For easy testing of the keyword extraction algorithm, we use online news articles as input documents. With the [Newspaper3k](https://newspaper.readthedocs.io/en/latest/) package this is very easy to do.\n",
    "\n",
    "**Side note:** Online news sites such Channel NewsAsia articles seem to be more convenient their content contains mainly ASCII characters. sites such as The Straits Times also contain Unicode characters for quotes, apostrophes, etc. As some extraction methods to specify such characters as boundary between keywords or keyword candidates, it's much easier if we can specify them in ASCII only. In practice, this can all be handled, but we want to keep it simple here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbac141a-63c0-496b-9378-40deece5d0ca",
   "metadata": {},
   "source": [
    "### Create `Article` Object\n",
    "\n",
    "We first create an `Article` object by giving our article URL of choice as input parameter to the constructor. Note that the code cell below does not actually download the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f79b7d6-aea8-40f7-91a3-e76625aa9feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.channelnewsasia.com/singapore/built-order-bto-waterway-sunrise-ii-project-delays-exceed-one-year-complete-housing-development-board-hdb-compensation-reimbursement-3324526\"\n",
    "url = \"https://www.channelnewsasia.com/singapore/focus-metaverse-another-fading-tech-fad-or-our-future-online-existence-3320981\"\n",
    "url = \"https://www.channelnewsasia.com/singapore/tiong-bahru-road-tree-collapse-bus-service-car-crushed-walkway-shelter-3322491\"\n",
    "\n",
    "article = Article(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9f71fe-f1b0-48f5-9a9d-3073375f834c",
   "metadata": {},
   "source": [
    "### Download & Analyze Article\n",
    "\n",
    "The code cell allow initiates the download ofthe news article as well as perform a basic analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053394e8-d69f-49f9-920d-54f9df353ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "article.download()\n",
    "article.parse()\n",
    "article.nlp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424dec1a-4d2b-4ad4-b271-103985901e44",
   "metadata": {},
   "source": [
    "### Inspect Keywords\n",
    "\n",
    "The analysis of the news article also includes a basic approach for extracting keywords. The approach is basic in the sense that all keywords are only individual words instead of any longer phrases. Still, let's have a look at the results so we can compare them with the results of the more sophistices keyword extraction methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd15b736-0950-4155-bfe3-ee351e855c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for keyword in article.keywords:\n",
    "    print(keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc704f38-9d43-436b-8c9c-70cb8c7de047",
   "metadata": {},
   "source": [
    "Lastly, we store the content of the article in variable `text` for use throughout the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380ff798-6063-4a82-bd5a-1b356c67193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = article.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce358ce-fe48-4e10-b1b0-ec6ec3a0343f",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "For the some of the keyword extraction methods used in this notebooks, it's recommended to perform some preprocessing. As mentioned above, it's convenient if the content contains only ASCII characters. The utility method below removes all line break characters. It then performs tokenization using spaCy but then concatenates all tokens again to a string. The difference is that there will be now a whitespace between each token (incl. punctuation marks, quotes, etc.). At least, the methods remove any remaining duplicated whitespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307133e4-88fb-4d9d-98f5-2c761562a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    # Remove line breaks\n",
    "    processed = re.sub('\\n', ' ', text)\n",
    "    # Use spaCy for tokenzing (seems to be convenient)\n",
    "    processed = ' '.join([ t.text for t in nlp(processed) ])\n",
    "    # Remove duplicate whitespaces\n",
    "    processed = re.sub('\\s+', ' ', processed)\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a08917-eea0-44f2-b390-c69f4419127d",
   "metadata": {},
   "source": [
    "We can now preprocess our news article and actually have a look at it. This will give a sense for what the article is about, which in turn allows to make some assessment what kind of keywords to expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74be374-bb76-462b-9451-c57a1c9a063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = preprocess(text)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5073d0f-9763-454b-bb60-6bfb6adbb87d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeb08d5-5011-4378-88d5-3894b1164a5b",
   "metadata": {},
   "source": [
    "## Keyword Extraction\n",
    "\n",
    "There are several basic keyword extraction algorithms that are commonly used in natural language processing and text analysis. Here are some of the most widely used algorithms:\n",
    "\n",
    "* **Frequency-based approach:** This method simply counts the number of occurrences of each word in a document and extracts the words with the highest frequency as keywords.\n",
    "\n",
    "* **TF-IDF (Term Frequency-Inverse Document Frequency) approach:** This method assigns a weight to each word in a document based on its frequency and its rarity across all documents in a corpus. The words with the highest TF-IDF score are extracted as keywords.\n",
    "\n",
    "* **RAKE (Rapid Automatic Keyword Extraction) algorithm:** This algorithm identifies candidate keywords based on their co-occurrence with other words in the text, and assigns each candidate a score based on its frequency of occurrence, the number of words in the keyword, and the degree to which the words in the keyword are separated from each other.\n",
    "\n",
    "* **YAKE (Yet Another Keyword Extractor) algorithm:** This algorithm combines both statistical and semantic features to identify the most relevant keywords or phrases in a text document, and assigns a score to each keyword based on its relevance to the text.\n",
    "    \n",
    "* **TextRank algorithm:** This algorithm uses a graph-based ranking method to identify the most significant sentences or keywords in a text document, based on the degree of similarity between the sentences.\n",
    "\n",
    "These basic keyword extraction algorithms can be applied to various types of text documents and can provide useful insights into the topics and concepts present in the text. However, they may have limitations in terms of accuracy and effectiveness, depending on the specific context and the quality of the text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d60dc1-4949-45ca-b842-6aa86d914505",
   "metadata": {},
   "source": [
    "### RAKE -- Rapid Automatic Keyword Extraction\n",
    "\n",
    "RAKE (Rapid Automatic Keyword Extraction) is a keyword extraction algorithm that was introduced by Stuart Rose, Dave Engel, Nick Cramer, and Wendy Cowley in a research paper in 2010. The RAKE algorithm is a simple and efficient technique for automatically extracting keywords or phrases from a text document. It works by first splitting the text into individual words and then identifying candidate keywords based on their co-occurrence with other words in the text.\n",
    "\n",
    "The RAKE algorithm assigns each candidate keyword a score based on its frequency of occurrence, the number of words in the keyword, and the degree to which the words in the keyword are separated from each other. The algorithm then selects the keywords with the highest scores as the final set of extracted keywords.\n",
    "\n",
    "One of the key advantages of the RAKE algorithm is its simplicity and speed. It does not rely on complex linguistic or statistical models, and it can process large amounts of text quickly and efficiently. However, the RAKE algorithm may not always produce the most accurate or representative set of keywords, as it does not take into account the semantic relationships between words or the context in which they appear."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9dfd05-f52b-49ff-a73a-75384f72b37a",
   "metadata": {},
   "source": [
    "#### Create `Rake` Object\n",
    "\n",
    "As we saw in the lecture, RAKE used stopwords, punctuation marks, and other user-defined characters to sepcify the boundaries of keywords. While `Rake` uses some meaingful default parameters, let's manually specidy the set `stopwords` the set of `punctuations` here. Since we have an English news article, it naturally to go with English stopword. In `punctuations` we put all common punctuation marks, brackets/parentheses, hypens, and quotes. But feel free to play with these sets and see the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc80931-1e4d-40f0-9a53-0feec3d127e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(sw.words('english'))\n",
    "punctuations = set([ c for c in \".,;:?!(){}[]-'\\\"\"])\n",
    "\n",
    "rake = Rake(stopwords=stopwords, punctuations=punctuations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20cebc3-a843-4682-82f2-3493110d0746",
   "metadata": {},
   "source": [
    "#### Extract Keywords\n",
    "\n",
    "By calling the method `extract_keywords_from_text()` we initiate the keyword extraction process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c219d9a4-799a-4281-9ecc-35294a194dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = \"Keyword keyword extraction is not that difficult after all. There are awesome libraries that can help you with keyword extraction. Rapid automatic keyword extraction is one of those.\"\n",
    "\n",
    "rake.extract_keywords_from_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248e31d9-cee5-45eb-b4fc-ed7354d69cd2",
   "metadata": {},
   "source": [
    "A keyword, particularly keywords with a high score, is likely to occur multiple times in the document. RAKE will return each individual instance. Since all instances of the same keyword will have the same score, we can remove duplicates to makes the result set look cleaner. The code cell below accomplishes this by adding all extracted keywords, together with their score to a set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b1c76c-9495-4074-9182-187b24bf7e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "rake_unique_keywords = set()\n",
    "\n",
    "for score, keyword in rake.get_ranked_phrases_with_scores()[:10]:\n",
    "    rake_unique_keywords.add((keyword.lower(), score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9c9176-a72f-47b4-acc5-4bc51ac09beb",
   "metadata": {},
   "source": [
    "Having all duplicates removed, we can now sort the keywords with respect to their score, as well as limit the result set to the top-10 keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db14b487-6808-40f8-b0e5-c6f3dec70df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rake_unique_keywords_sorted = sorted(rake_unique_keywords, key=lambda tup: tup[1], reverse=True)[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12d3a87-aef9-476f-a549-480d8e402786",
   "metadata": {},
   "source": [
    "Lastly, we can print the top keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea98cdb-8ba9-4451-9d42-f1c060204d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for keyword, score in rake_unique_keywords_sorted:\n",
    "    print(\"{:.3f}:\\t{}\".format(score, keyword))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd304e10-5cae-4882-8194-f5cebeeb6d72",
   "metadata": {},
   "source": [
    "### YAKE! -- Yet Another Keyword Extractor\n",
    "\n",
    "YAKE (Yet Another Keyword Extractor) is a keyword extraction algorithm that was introduced in a research paper in 2018. It is a state-of-the-art algorithm that is designed to automatically extract keywords or phrases from a text document by considering both their statistical properties and their semantic meanings. The YAKE algorithm works by first identifying candidate keywords based on their statistical properties such as their frequency of occurrence, length, and position in the text. It then uses a language model and a graph-based ranking method to evaluate the relevance of each candidate keyword to the text.\n",
    "\n",
    "The language model used in YAKE is based on a concept called \"term specificity,\" which measures how much information a word provides about the topic of the document. The graph-based ranking method considers the relationships between words in the text and uses this information to assign a score to each candidate keyword. One of the key advantages of the YAKE algorithm is its ability to handle multi-word expressions and phrases as keywords. It also considers the context and meaning of the text when extracting keywords, which can result in a more accurate and representative set of keywords. Additionally, the YAKE algorithm is highly customizable, allowing users to adjust the parameters and weights of the algorithm to suit their specific needs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a3bd8c-0d50-4daf-9a02-9e84448cf063",
   "metadata": {},
   "source": [
    "#### Create `yake.KeywordExtractor` Object\n",
    "\n",
    "Similar to RAKE, the YAKE! implementation supports a series of input parameters; see below for a concrete example. However, let's first run it with the default parameters which reflect the values for the parameters that have been identified using parameter tuning in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d844e12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yake_keyword_extractor = yake.KeywordExtractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebf652c-ae2b-4812-b65d-598638677b37",
   "metadata": {},
   "source": [
    "#### Extract Keywords\n",
    "\n",
    "By calling the method `extract_keywords()` we initiate the keyword extraction process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87195fbf-db37-49ba-af3e-0557f685f722",
   "metadata": {},
   "outputs": [],
   "source": [
    "yake_keywords = yake_keyword_extractor.extract_keywords(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba64ca05-6089-4f62-a17f-db9ffdd2603b",
   "metadata": {},
   "source": [
    "As the YAKE! algorithm -- or at least this implementation of the algorithm -- does no return duplicates, we can directly print the top keywords. Since we don't remove duplicates using a `set()`, there is no need to sort the keywords as they are already sorted. By default, the algorithm return the top-20 keywords. Note that in case of Yake!, the lower the score the better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7c5021-d171-44d7-b4f9-815900e15594",
   "metadata": {},
   "outputs": [],
   "source": [
    "for keyword, score in yake_keywords:\n",
    "    print(\"{:.6f}:\\t{}\".format(score, keyword))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c290f573-075d-489e-8726-56f05051231f",
   "metadata": {},
   "source": [
    "#### Using a Custom `yake.KeywordExtractor` Object\n",
    "\n",
    "In the code cell below, we again create a `yake.KeywordExtractor` object, but this time we specify the input parameters explicitly. Note, however, that the values below represent in fact the default values; apart form `top` which is set to 10 instead of 20. You can change the values of these parameter to see how it affects the result keyword list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8668e7-3484-44d5-83c8-997796c1672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "language = \"en\"\n",
    "max_ngram_size = 3\n",
    "deduplication_threshold = 0.9\n",
    "deduplication_algo = 'seqm'\n",
    "window_size = 1\n",
    "num_of_keywords = 10\n",
    "\n",
    "yake_keyword_extractor = yake.KeywordExtractor(lan=language, \n",
    "                                               n=max_ngram_size, \n",
    "                                               dedupLim=deduplication_threshold, \n",
    "                                               dedupFunc=deduplication_algo, \n",
    "                                               windowsSize=window_size,\n",
    "                                               top=num_of_keywords,\n",
    "                                               features=None)\n",
    "\n",
    "yake_keywords = yake_keyword_extractor.extract_keywords(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bd0d34-b30a-409a-af63-6748c46a761d",
   "metadata": {},
   "source": [
    "We the `yake.KeywordExtractor` we can extract and display the top keywords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f86d64-e4e5-4a80-bc64-53c288e7f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "yake_keywords_sorted = sorted(yake_keywords, key=lambda tup: tup[1], reverse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dba4bb6-2527-4af2-ae09-8569db983d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for keyword, score in yake_keywords_sorted:\n",
    "    print(\"{:.6f}:\\t{}\".format(score, keyword))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06762b63-a8fb-40d6-b1a3-9a5a6c84f92c",
   "metadata": {},
   "source": [
    "### TextRank\n",
    "\n",
    "TextRank is a keyword and sentence extraction algorithm that was introduced in a research paper by Mihalcea and Tarau in 2004. It is a graph-based ranking algorithm that uses a variation of the PageRank algorithm to identify the most significant sentences or keywords in a text document. The TextRank algorithm works by first breaking the text into individual sentences and then creating a graph representation of the text, with each sentence represented as a node in the graph. The algorithm then assigns weights to the edges between the nodes based on the degree of similarity between the sentences.\n",
    "\n",
    "The similarity between sentences is determined using a measure of semantic similarity, such as cosine similarity, which compares the vectors of the words in the sentences. The TextRank algorithm then calculates the importance score of each sentence or keyword by applying a variant of the PageRank algorithm to the graph representation of the text. The resulting scores represent the relative importance of each sentence or keyword in the text, with higher scores indicating greater significance. The TextRank algorithm can be used for both keyword extraction and summarization, with the top-ranked keywords or sentences representing the most important concepts and ideas in the text.\n",
    "\n",
    "One of the key advantages of the TextRank algorithm is its ability to identify important concepts and relationships between concepts in a text document, rather than just individual keywords or sentences. This can result in a more comprehensive and accurate summary or representation of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f415f683-15c7-4f4a-bc3e-2a05739a22a7",
   "metadata": {},
   "source": [
    "#### Extract Keywords\n",
    "\n",
    "When setting up the notebook, we already added the implementation of TextRank to the spaCy pipeline. This means that we can spaCy to analyze our news article as usual, and spaCy will extract all keywords using the TextRank algorithm. Similar to Rake, the TextRank result might contain duplicated occurrences of the same keyword (but with using different captilization, for example). So we again use a `set()` to easily remove those duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b16873-9558-423d-becb-e61aec0512a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)\n",
    "\n",
    "textrank_unique_keywords = set()\n",
    "\n",
    "for phrase in doc._.phrases:\n",
    "    textrank_unique_keywords.add((phrase.text.lower(), phrase.rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33aee02-d0ab-4ae4-8eb0-f14f126bb39d",
   "metadata": {},
   "source": [
    "This intermediate step of removing the duplicates requires that we have to sort the keywords again; we also limit the result to the top 10 keywords to be consistent with the outer outputs above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1f1f92-e25e-4657-bc43-a95750c9aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "textrank_unique_keywords_sorted = sorted(textrank_unique_keywords, key=lambda tup: tup[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3baea4fb-f032-4aad-82fa-4eeadcce3286",
   "metadata": {},
   "source": [
    "As the last step, we print the top keywords and compare them to the result from the other algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316001d4-53e3-453b-bd0e-09f65f4dd0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for keyword, score in textrank_unique_keywords_sorted:\n",
    "    print(\"{:.3f}:\\t{}\".format(score, keyword))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16717de9-5f92-4d5d-929f-27d8854ff1e3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d44973b-6275-47f9-a8ff-164b42bbb987",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Rake, Yake, and TextRank are all keyword extraction algorithms that use different techniques to identify the most important keywords or phrases in a text document. Here are some of the key differences between these algorithms:\n",
    "\n",
    "* **Approach:** Rake uses a statistical approach that is based on the co-occurrence of words in a text, while Yake uses a combination of statistical and semantic approaches to identify relevant keywords. TextRank uses a graph-based approach that considers the relationships between sentences in a text.\n",
    "\n",
    "* **Multi-word expressions:** Yake and TextRank are capable of extracting multi-word expressions and phrases as keywords, while Rake can only extract individual words as part of the core algorithm.; Rake for multi-word keywords as a kind postprocessing step.\n",
    "\n",
    "* **Performance:** Yake is considered to be a state-of-the-art keyword extraction algorithm with high accuracy, while Rake and TextRank are more basic algorithms that may be less accurate but faster to compute.\n",
    "\n",
    "* **Customization:** Yake allows for more customization of the algorithm parameters and weights than Rake and TextRank, making it more adaptable to specific contexts and data sets.\n",
    "\n",
    "* **Application:** While all three algorithms can be used for keyword extraction, TextRank is also commonly used for text summarization, as it can identify the most important sentences in a text document.\n",
    "\n",
    "Overall, the choice of which algorithm to use for keyword extraction will depend on the specific goals and requirements of the analysis, as well as the characteristics of the text data being analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22ea39c-5234-40c3-bb41-d72d08c4c235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs5246]",
   "language": "python",
   "name": "conda-env-cs5246-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
